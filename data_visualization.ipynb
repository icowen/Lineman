{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(3)\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\ian_c\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column PassResult - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "     X        gameId  playId  frame.id  OL_C_x     OL_C_y  OL_LG_x    OL_LG_y  \\\n0  1.0  2.017091e+09    68.0       1.0   26.59  23.433332    26.16  24.993334   \n1  2.0  2.017091e+09    68.0       2.0   26.59  23.423334    26.16  24.993334   \n2  3.0  2.017091e+09    68.0       3.0   26.58  23.423334    26.16  24.993334   \n3  4.0  2.017091e+09    68.0       4.0   26.58  23.423334    26.16  24.993334   \n4  5.0  2.017091e+09    68.0       5.0   26.57  23.423334    26.16  24.983334   \n\n     OL_LT_x    OL_LT_y  ...    Def_9_x    Def_9_y   Def_10_x   Def_10_y  \\\n0  26.030001  26.723333  ...  35.380001  35.143333  42.490002  24.393333   \n1  26.030001  26.723333  ...  35.369999  35.143333  42.490002  24.403334   \n2  26.030001  26.723333  ...  35.369999  35.143333  42.500000  24.413334   \n3  26.030001  26.723333  ...  35.369999  35.143333  42.520000  24.453333   \n4  26.030001  26.723333  ...  35.369999  35.153332  42.639999  24.673334   \n\n    Def_11_x   Def_11_y  PlayResult  sack.ind  PassResult  num_vec  \n0  28.469999  43.843334         0.0       0.0           I      1.0  \n1  28.469999  43.843334         0.0       0.0           I      2.0  \n2  28.469999  43.843334         0.0       0.0           I      3.0  \n3  28.469999  43.843334         0.0       0.0           I      4.0  \n4  28.480000  43.843334         0.0       0.0           I      5.0  \n\n[5 rows x 62 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>gameId</th>\n      <th>playId</th>\n      <th>frame.id</th>\n      <th>OL_C_x</th>\n      <th>OL_C_y</th>\n      <th>OL_LG_x</th>\n      <th>OL_LG_y</th>\n      <th>OL_LT_x</th>\n      <th>OL_LT_y</th>\n      <th>...</th>\n      <th>Def_9_x</th>\n      <th>Def_9_y</th>\n      <th>Def_10_x</th>\n      <th>Def_10_y</th>\n      <th>Def_11_x</th>\n      <th>Def_11_y</th>\n      <th>PlayResult</th>\n      <th>sack.ind</th>\n      <th>PassResult</th>\n      <th>num_vec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.017091e+09</td>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>26.59</td>\n      <td>23.433332</td>\n      <td>26.16</td>\n      <td>24.993334</td>\n      <td>26.030001</td>\n      <td>26.723333</td>\n      <td>...</td>\n      <td>35.380001</td>\n      <td>35.143333</td>\n      <td>42.490002</td>\n      <td>24.393333</td>\n      <td>28.469999</td>\n      <td>43.843334</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>I</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>2.017091e+09</td>\n      <td>68.0</td>\n      <td>2.0</td>\n      <td>26.59</td>\n      <td>23.423334</td>\n      <td>26.16</td>\n      <td>24.993334</td>\n      <td>26.030001</td>\n      <td>26.723333</td>\n      <td>...</td>\n      <td>35.369999</td>\n      <td>35.143333</td>\n      <td>42.490002</td>\n      <td>24.403334</td>\n      <td>28.469999</td>\n      <td>43.843334</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>I</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>2.017091e+09</td>\n      <td>68.0</td>\n      <td>3.0</td>\n      <td>26.58</td>\n      <td>23.423334</td>\n      <td>26.16</td>\n      <td>24.993334</td>\n      <td>26.030001</td>\n      <td>26.723333</td>\n      <td>...</td>\n      <td>35.369999</td>\n      <td>35.143333</td>\n      <td>42.500000</td>\n      <td>24.413334</td>\n      <td>28.469999</td>\n      <td>43.843334</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>I</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>2.017091e+09</td>\n      <td>68.0</td>\n      <td>4.0</td>\n      <td>26.58</td>\n      <td>23.423334</td>\n      <td>26.16</td>\n      <td>24.993334</td>\n      <td>26.030001</td>\n      <td>26.723333</td>\n      <td>...</td>\n      <td>35.369999</td>\n      <td>35.143333</td>\n      <td>42.520000</td>\n      <td>24.453333</td>\n      <td>28.469999</td>\n      <td>43.843334</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>I</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>2.017091e+09</td>\n      <td>68.0</td>\n      <td>5.0</td>\n      <td>26.57</td>\n      <td>23.423334</td>\n      <td>26.16</td>\n      <td>24.983334</td>\n      <td>26.030001</td>\n      <td>26.723333</td>\n      <td>...</td>\n      <td>35.369999</td>\n      <td>35.153332</td>\n      <td>42.639999</td>\n      <td>24.673334</td>\n      <td>28.480000</td>\n      <td>43.843334</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>I</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 62 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 34
    }
   ],
   "source": [
    "data = pd.read_csv('netdata.csv', dtype='float32', converters={'PassResult': lambda x: 'R' if pd.isna(x) else x})\n",
    "data = data.drop(data[~data[\"playId\"].isin(data[\"playId\"].unique()[:10])].index)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New dimensions of DataFrame: (2490, 61)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data.drop('X', inplace=True, axis=1)\n",
    "data.fillna('Run', inplace=True)\n",
    "print(f'New dimensions of DataFrame: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of unique plays: 10\n",
      "Average number of frames per play 249.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "num_plays = data[\"playId\"].unique().size\n",
    "print(f'Number of unique plays: {num_plays}')\n",
    "print(f'Average number of frames per play {round(data.shape[0] / num_plays, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Title](play68.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[189. 210. 395. 427. 449.]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "last_5_play_ids = data[\"playId\"].unique()[-5:]\n",
    "test_data = data.loc[data[\"playId\"].isin(last_5_play_ids)]\n",
    "train_data = data.loc[~data[\"playId\"].isin(last_5_play_ids)]\n",
    "print(last_5_play_ids)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index(['gameId', 'playId', 'frame.id', 'OL_C_x', 'OL_C_y', 'OL_LG_x',\n",
      "       'OL_LG_y', 'OL_LT_x', 'OL_LT_y', 'OL_RG_x', 'OL_RG_y', 'OL_RT_x',\n",
      "       'OL_RT_y', 'X_Match_LT', 'Y_Match_LT', 'X_Match_LG', 'Y_Match_LG',\n",
      "       'X_Match_C', 'Y_Match_C', 'X_Match_RG', 'Y_Match_RG', 'X_Match_RT',\n",
      "       'Y_Match_RT', 'Off_1_x', 'Off_1_y', 'Off_2_x', 'Off_2_y', 'Off_3_x',\n",
      "       'Off_3_y', 'Off_4_x', 'Off_4_y', 'Off_5_x', 'Off_5_y', 'Off_6_x',\n",
      "       'Off_6_y', 'Def_1_x', 'Def_1_y', 'Def_2_x', 'Def_2_y', 'Def_3_x',\n",
      "       'Def_3_y', 'Def_4_x', 'Def_4_y', 'Def_5_x', 'Def_5_y', 'Def_6_x',\n",
      "       'Def_6_y', 'Def_7_x', 'Def_7_y', 'Def_8_x', 'Def_8_y', 'Def_9_x',\n",
      "       'Def_9_y', 'Def_10_x', 'Def_10_y', 'Def_11_x', 'Def_11_y', 'PlayResult',\n",
      "       'sack.ind', 'PassResult', 'num_vec'],\n",
      "      dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(test_data.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "keep_regex = r'(Off|OL_(<?(C|LG|RG|RT|LT)_(x|y))$|Def|frame|Match)'\n",
    "keep_cols = [c for c in train_data.columns if not re.search(keep_regex, c)]\n",
    "data_train_for_model = train_data.drop(keep_cols, axis=1)\n",
    "data_test_for_model = test_data.drop(keep_cols, axis=1)\n",
    "\n",
    "input_shape = (data_train_for_model.shape[1],)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "num_input_nodes = 25\n",
    "num_output_nodes = 1\n",
    "model.add(tf.keras.layers.Dense(num_input_nodes, input_shape=input_shape, activation=tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(num_input_nodes, activation=tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(num_input_nodes, activation=tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(num_output_nodes, activation=tf.keras.activations.linear))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def mse_loss_with_prior(avg_of_play_no_noise):\n",
    "    def mse(y_true, y_pred):\n",
    "        return K.mean(K.square((y_pred - avg_of_play_no_noise) - y_true))\n",
    "\n",
    "    return mse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=mse_loss_with_prior([]),\n",
    "              metrics=['acc'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "initial_model = tf.keras.models.clone_model(model)\n",
    "initial_weights = model.get_weights()\n",
    "initial_model.set_weights(initial_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[-1.9341649]\n",
      " [-1.9341817]\n",
      " [-1.9341805]\n",
      " [-1.9341414]\n",
      " [-1.9342172]\n",
      " [-1.9343321]\n",
      " [-1.9343932]\n",
      " [-1.9343791]\n",
      " [-1.9346864]\n",
      " [-1.93153  ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "initial_predictions = initial_model.predict(data_train_for_model)\n",
    "print(initial_predictions[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\ian_c\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-952a5c157194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.compile(loss=mse_loss_with_prior(train_data[\"NetNoise\"]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(train_data.drop([c for c in train_data.columns if not re.search(keep_regex, c)], axis=1).head().to_string())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NetNoise\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Linesman\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    583\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_4_input to have shape (55,) but got array with shape (62,)"
     ],
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_4_input to have shape (55,) but got array with shape (62,)",
     "output_type": "error"
    }
   ],
   "source": [
    "prior = 4.0\n",
    "train_data[\"NetNoise\"] = initial_predictions - prior\n",
    "# model.compile(loss=mse_loss_with_prior(train_data[\"NetNoise\"]))\n",
    "# print(train_data.drop([c for c in train_data.columns if not re.search(keep_regex, c)], axis=1).head().to_string())\n",
    "pred = model.predict(train_data).flatten()\n",
    "\n",
    "pred.flatten() - train_data[\"NetNoise\"].values[:len(pred)]\n",
    "# train_data[\"NetNoise\"]\n",
    "# pred - train_data[\"NetNoise\"].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Linesman)",
   "language": "python",
   "name": "pycharm-84726f9f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}